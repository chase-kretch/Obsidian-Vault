
### Lecture 04 Virtual Machines 2

- Virtualisation Implementation
	- Generally difficult to make a exact duplicate of a machine
		- Especially if only dual mode on CPU
		- CPU features and support for VMMs (Virtual Machine Manager), it is getting easier
	- Most VMMs implement virtual CPU to represent states of each VM
		- When guest context switched onto CPU by manager, information from VCPU is loaded and storage
- Trap and Emulate
	- Dual mode CPU: virtual machine guest executes in usermode
	- Just as the physical machine has two modes, so much the VM
		- VM needs two modes, V usermode and V Kernel mode, both run in real user mode
	- Actions in guest that usually cause switch to kernel mode must cause switch to VKM
	- Attempting priviledge instruction in user mode causes and error (trap)
	- VMM gains control, checks error, and executes operation as attempted by guest (emulate)
	- Return control to guest in user mode
	- User mode code in guest runs at same speed as if not a guest
		- Kernel mode code instead runs slower due to trap and emulate
		- Especially when multiple guests are running, (each need trap and emulate)
	 - Now that there is support for VMMs, CPUs tend to do this far better.
- Virtualization Problems
	- Some cpus dont have clean separation between privileged and nonprivileged instructions
		- Earlier x86 CPUs
		- x86 popf
			- Load CPU flags register from contents of the stack
			- If CPU in privileged mode, all flags replaced
			- If user mode, only some are replaced
			- No trap generated
	- Special Instructions caused:
		- Until 1998, trap-emulate was considered impossible
		- **Binary Translation** solves this
			- If guest VCPU is in usermode, guest can run instructions natively.
			- If kernel mode,
				- VMM examines every instruction guest is about to execute by reading ahead
				- Non special instructions run natively
				- Special instructions translated at runtime into new instructions that do equivalent task
		- Not slow because
			- Translation is simple
			- Only translates code that is ran
			- Much is the same as original
			- Cached and reused
			- Other tricks
	- **Memory Management**
		- Another challenge.
		- How can a VMM keep page table state for both guests believing they control the page and VMM that controls the tables
		- Commonly used **nested page tables (NPTs)**
			- For trap and emulated and binary translation.
			- Each guest maintains page tables to translate virtual to physical address
			- VMM maintains per guest NPT to represt guest page table
			- Just as VPU stores guest CPU state
			- When guest CPU, VMM makes the guests NPT the active page table
			- Causes TLB misses, slow performance
	- **Hardware**
		- All virtualisation needs some HW support
		- Intel added VT-x AMD AMD-V (2005 2006)
			- CPUs with this dont need binary translation
			- Defines more CPU modes, guest host
		- HW support for NPT, DMA and interrupts.
- **More VM styles**
	- Application Containment (OS Level Virtualisation)
		- Good for servers (use same OS)
		- Containers look like servers, they can be rebooted separately, have their own ip, root, programs, but use **same kernel**.
	- Paravirtualisation
		- Xen - requires modifying OS source code to use xen layer, guest knows it is running off a host.
	- Application Virtualisation
		- Application runs on a layer which provides resources it needs even though it may be running on a different OS. Wine for running programs from old windows on a newer one. (Wine is not an emulator)
	- Programming-Environment Virtualisation
		- Java Vm, CLR/MONO
		- Implement different architecture on top of hardware /OS
	- Windows Subsystem for Linux 

## Lecture 05 Systems Programming Language

- C is the language of choice for majority of OS.
	- High level assembler, can do low level things such as accessing and modifying memory.
	- Also is portable (can be used on different architectures)
	- ![[Pasted image 20240729012552.png]]
- Accessing Registers
	- You can use the register storage class specifier to say that a variable should be kept in the register e.g
		- register long number = 1234
	- However this doesnt guarantee that the value is stored in the register, it depends on how many available registers there are
	- Also, compilers are good at optimising register usage and it isnt a good idea for a programmer to manually do this
	- memory mapped registers can be accessed directly using pointer manipulation
- Volatile
	- Volatile is a type qualifier
		- volatile unsigned char *reg
		- This means the variable may change in a non local way, or that the compiler has no way of knowing whether the value has changed or not between references
		- Compiler is not allowed to optimise accesses. Ever read must go back to the main store to retrieve the current value
			- memory mapped device registers
			- values modified in interrupt routines
			- values modified in another thread
- Memory Management
	- All local variables disappear when functions are returned
		- Space is allocated on the stack for the variables in each function invocation
		- There is a limit to stack size soft limites asnd hard limits. 
	- Areas of static memory
		- Global Variables
		- Static variables
		- If in a function it maintains its value even when the function is returned. Where is the variable actually stored?
	- The advantage of static memory is that it is allocated at compile time and hence has no allocation overhead at ruin time.
	- The disadvantage is that it cannot easily be released.
- Dynamic Memory
	- C requires explicit control of dynamic memory
		- This is suitable for OS programming as there is no garbage collection available
		- garbage collection adds a layer of complexity and unpredictability to the programming environment
		- this is important in small systems such as embedded systems (or phones)
		- especially important in real-time syustems
		- malloc or callic
		- free(thread)

## Lecture 6

Processes and Threads

- Process
	- The thing which represents our work to the systemm
	- Sometimes referred to as a heavyweight process
		- I instance of a program in execution
	- May be more than one version of the same program running at the same time (hopefully sharing the code), each instance has resources limitations, security information, rights, capabilities etc.
	- So it includes code, data, connections (to files networks and other processes) access to devices
	- It needs the processor to run, but it doesnt run all the time. So it needs information about what it is up to stored somewhere
- Two parts to a process
	- 1, Resources, the things that the process owns (may be shared) also information about the process
	- 2, What the process is doing - streams of execution
	- Traditin processes had resources and a single current location e.g traditional UNIX. The resource part is called a task or a job. The location part is commonly called a thread
	- Most operating systems now provide support to keep these parts separate e.g Linux, Solaris, Windows and MacOS
- Threads
	- Sometimes referred to as lightweight processes
	- A sequence of instuructions being executed when there is no external intervention.
	- Multiple threads of a process, share the prcess resources but have their own thread ID, PC, registers and stack
	- Easier to create than a process. They provide a nice encapsuilation of a problem within a process rather than multiple processes
	- Easier to switch between threads than between processes.
	- Typical Uses
		- Splitting work across processors (shared memory multiprocessor, multiple cores)
		- added responsiveness (handle user input while still finishing another function)
		- controlling and monitoring other threads
		- server applications
		- can help with program abstraction
	- Thread implementation
		- User-level (green threads)
			- The OS only sees one thread per process
			- The process constructs other threads by user-level library calls or by hand
			- user-level control over starting and stopping threads
			- usually a request is made to the OS to interrupt the process regularly (an alarm clock) so that the process can schedule another thread
			- The state of threads in the library code does not correspond to the state of the process
		- System-level
			- The OS knows about multiple threads per process 
			- Threads are constructed and controlled by system calls
			- The system knows the state of each thread
		- User-level advantages
			- Works even if the OS doesnt support threads
				- Some implementations of Java had user-level threads because the underlying OS didnt
			- Easier to create- no system call
				- Just normal library procedure call
				- No switch into kernel mode (this saves time)
			- Control can be application specific
				- Sometimes the OS doesn't give the type of control an application needs
				- e.g Precise priority levels, changing scheduling decisions according to state changes
			- Easier to switch between - saves processor mode changes
				- Can be as simple as saving and loading registers (including SP, PSW and PC)
			- The reason this isn't always better  than system-level threads is because the OS only sees one thread per process so e.g if the thread is waiting for I/O the whole system will wait for I/O
		- System-Level thread advantages
			- Each thread can be treated separately
				- Rather than using the timeslice of one process over many threads
				- Should a process with 100 threads get 100 times the CPU time of a process with 1 thread.
					- No! All threads have their individual CPU time and priority
			- A thread blocking in the kernel doesn't stop all other threads in the same process
				- With user-level threads if one thread blocks for I/O the OS sees the process as blocked for I/O even if there are other threads running
			- On a multiprocess (including multi-core) different threads can be scheduled on different processores
				- This can only be done if the OS knows about the threads
				- Even then it sometimes doesnt work -standard Python has system level threads but the Global Interpreter Lock (GIL) means that only one runs at a time even on a multicore machine
		- Which of these can't be done with User-level threads?
			- Splitting work across processes (shared memory multiprocessir, multiple cores)
				- No! Because the operating system sees the process as one
			- Added responsiveness (handle user input while finishing another function)
				- No (atleast not efficient), the OS will view the user-input threads of a process a single thread and once one is waiting for I/O the process will be considered blocked/waiting
			- Controlling and monitoring other threads
				- Is possible at user level as we dont need multiple processes running
			- Server Applications
				- It is possible with user level threads but to use multithreading and multicore CPUs we need server threads
			- Can help program abstraction
				- Yes, both system and user level are useful for concurrent programs
	- Jacketing
		- One major problem is user-level threads is the blocking of all threads within a process when one blocks
		- A possible solution is known as jacketing
			- A blocking system call has a user-level jacket
			- The jacket checks to see if the resource is available e.g device is free
			- If not another thread is started
			- When calling thread is scheduled again (by the thread library) it once again checks the state of the device
		- So there has to be some way of determining is resources are available to accept requests immediately
	- The best of both worlds
		- Solaris (versions < 9) had both user-level and ssytem-level threads.
		- LWP (light weight process) what we call system level threads)
		- Kernel Threads - active within the kernel
			- Each LWP is associated with one kernel thread
		- One or more user threads could be multiplexed on each LWP
		- A process could have several user and several LWPs
		- The number of LWPs per process as adjusted automatically to keep threads running
			- If all LWPs in process block, but there are user level threads which could run kernel creates new LWP
		- ![[Pasted image 20240806020610.png]]
	- Original Linux Threads (before 2.6)
		- Thread creation is done through clone() system call.
		- Clone() makes a new process
			- Shares memory address space, open files, signal handlers)
		- From one point of view original Linux threads were processes but they shared all resources and hence the advantages of threads
		- original LINUX threads and POSIX
			- Cant be set to schedule according to priority within a process
				- Each thread is scheduled independently across all threads/processes in the system
			- Cant send a signal to the whole process
			- Ordinary system calls e.g read were nto cancellation points
			- Starting a new program in one thread doesn't kill the other threads in the same process
			- When an original Linux thread blocks doing IO do all other threads in the same process stop?
## Lecture 7
 Memory Layout of C Program
- PThread Programming
	- POSIX threads or ptrheads are used in UNIX type operating systems
	- Use "man pthread_create" to get the manual page
	- ![[Pasted image 20240806171331.png]]
	- The #include needs to be added to the top of your source file
	- going through the parameters
		- thread is a pointer to a pthread_t type - this is where information about the thread is stored, we need this to join the thread when we wait for it to finish
		- attr is a pointer to pthread attributes, to use the default we put NULL
		- start_routine is the name of the function which the thread runs
		- arg is a pointer to arguments/parameters used by the function
	- Making sure a PThread has finished
		- ![[Pasted image 20240806172455.png]]
	- A thread function
		- To keep our compiler happy our thread function must be of the type:
			  void \*(\*start_routine) (void \*)
		- The start_routine is a pointer to a function. In C this is exactly the same as a function name
		- The function returns a pointer to a void (i.e, it can return a pointer to anything, we can cast it)
		- The function accepts one parameter which is also a pointer to a void (i,e we can make it point to anything)
			- void \*the_function(void \*params) {...}
		- We run this in a thread by calling:
			- pthread_create(&thread_info, NULL, the_function, (void \*) &args)
			- Where args is a pointer to the values we want to send to the function, and thread_info is a pthread_t.
				- pthread_t thread_info;
		- ![[Pasted image 20240806173300.png]]
- Memory Layout of a C Program
	- ![[Pasted image 20240806173422.png]]
	- Segmentation Fault
		- Each region has its own set of permissions. For example. the code segment is usually marked as real-only to prevent accidental modification of the program code.
		- Situations we may get a segmentation fault:
			- Accessing unitialized memory
			- Dereferencing a null pointer
			- Stack overflow
			- Accessing memory outside of its allocated space
	- Address translation
		- Virtual address spaces = pages
		- Physical address space = frames
		- How do we map virtual to physical
		- Page tables map virtual to physical
	- Benefits of Memory Mapping
		- Efficient use of physical memory
			- By allowing multiple processes to share the same physical memory, the operating system can use memory more efficiently
		- Protection
			- Each process has its own virtual memory space, which provides protection against other processes accessing its memory
		- large address space
			- Virtual memory allows each process to have a larger virtual address space than is available in physical memory
		- 
			  
## Lecture 8
- Process Control Block (PCB)
	- Information associated with each process (also called task control block)
	- Where the OS can find all the information it needs to know about a process
		- Process identified and manged via a process identifier (pid)
		- Process state, running waiting, etc
		- Program counter
		- CPU registers
			- contents of all process-centric registers
		- CPU scheduling information
			- priorities, scheduling queue pointers
		- Memory-management information
			- memory allocated to the process
		- Accounting information
			- CPU used, clock time elapse since start, time limits
		- I/O status
			- I/O devices allocated to process, list of open files
	- Doesnt have to be kept together
	- ![[Screenshot 2024-08-01 at 2.14.05 PM.png]]
- UNIX PCBs
	- The PCB is the box labelled process structure but the user structure maintains some of the information as well (only required when the process is resident)
	- ![[Screenshot 2024-08-01 at 2.16.05 PM.png]]
- Windows NT PCBs
	- Information is scattered in a variety of objects
	- Executive Process Block (EPROCESS) includes:
		- KPROCESS and PEB (Process Environment Block)
			- KPROCESS includes info the kernel needs to scheduele threads
				- Kernel and user times
				- Pointers to threads
				- Priority information
				- 
			
		- Points to threads
		- Priotity information
- ![[Screenshot 2024-08-01 at 2.23.03 PM.png]]
- Linked together with a doubley linked list
- Process State
	- As a process executes it changes state
		- New: the process is being created
		- Running: being executed
		- Waiting: pending for some event to occur
		- Ready: the process is waiting to be assigned to a processor
		- Terminated: finished executing
		- ![[Screenshot 2024-08-01 at 2.25.22 PM.png]]
- Process Creation
	- Different methods of creating processes
		- Create process system call
			- takes a program name or a stream with the program data
			- windows
		- copy process system call
			- A strange way of doing it but is now very widespread thanks to UNIX
		- Create a new terminal session
		- Requires
			- A spare or new PCB
			- mark it new
			- generate a unique identifier
			- get some memory (what if there isnt any) or
			- fill in page table entries
			- set up PCB fields with initial values
			- set priority and resource limits
			- change state to ready
			- can be done by inserting into a queue of runnable processes
		- What about other resources?
			- Some OS' carefully allocate resources before a process runs (this prevents deadlock later)
			- Others leave these to the process to collect as it runs
		- Address space
			- Child duplicate of parent 
				- each one has its own copy of any data
				- Child has a new program loaded into it
			- UNIX Examples
				- fork() system call creates a new process
				- exec() system call used after a fork() to replace the processes memory space with a new program
				- Parent process calls wait() waiting for the child to terminate
				- ![[Screenshot 2024-08-01 at 2.35.45 PM.png]]
	- UNIX Fork() Call
		- Parent process
			- the one who made the call
		- Child
			- new process
		- Traditionally memory was duplicated - the code was shared even from earliest days
			- Share open files as well
			- Open file information will have the count of processes using them increases by one
			- And shared memory regions
			- Fork returns 0 in the child process and the childs pid in the parent
			- ![[Screenshot 2024-08-01 at 2.40.05 PM.png]]
			- ![[Screenshot 2024-08-01 at 2.48.51 PM.png]]
			- 6 times
	- Exec() System call
		- Checks to see if the file is executable
		- saves any parameters in some system memory
		- releases currently held memory
		- loads the program
		- moves the save parameters into the stack space of the new program
		- ready to run again
	- Fork used to copy the data memory of the process
	- If the child is going to do na exec this is a waste of effort
	- particularly bad with virtual memory
	- 